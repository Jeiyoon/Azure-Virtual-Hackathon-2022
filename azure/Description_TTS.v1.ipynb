{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4b38965",
   "metadata": {},
   "source": [
    "# 1. 라이브러리 설치하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8cb1f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5.5\n"
     ]
    }
   ],
   "source": [
    "#라이브러리 호출\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "print(cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "934abf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-cognitiveservices-vision-computervision in c:\\users\\ansrl\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\users\\ansrl\\anaconda3\\lib\\site-packages (from azure-cognitiveservices-vision-computervision) (1.1.28)\n",
      "Requirement already satisfied: msrest>=0.5.0 in c:\\users\\ansrl\\anaconda3\\lib\\site-packages (from azure-cognitiveservices-vision-computervision) (0.6.21)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\ansrl\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.3.1)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\ansrl\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (0.6.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ansrl\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2021.10.8)\n",
      "Requirement already satisfied: requests~=2.16 in c:\\users\\ansrl\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.26.0)\n",
      "Requirement already satisfied: six in c:\\users\\ansrl\\anaconda3\\lib\\site-packages (from isodate>=0.6.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ansrl\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ansrl\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ansrl\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ansrl\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade azure-cognitiveservices-vision-computervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9d4c95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\ansrl\\anaconda3\\lib\\site-packages (8.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde065ba",
   "metadata": {},
   "source": [
    "# 2. Azure Cognitive Service 이미지분석 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d87f8b",
   "metadata": {},
   "source": [
    "### ※ 참고사항!\n",
    "\n",
    "#### 1) URL 기반으로 Description 만들 때 : Describe_image 메써드 사용\n",
    "- Azure Cognitive Services Computer Vision SDK for Python : 이게 BEST\n",
    "https://docs.microsoft.com/ko-kr/python/api/overview/azure/cognitiveservices-vision-computervision-readme?view=azure-python\n",
    "\n",
    "- <참고만> : 오류뜸 https://docs.microsoft.com/ko-kr/azure/cognitive-services/computer-vision/quickstarts-sdk/image-analysis-client-library?tabs=visual-studio&pivots=programming-language-python\n",
    "\n",
    "- <참고만> : 오류뜸 https://docs.microsoft.com/ko-kr/azure/cognitive-services/computer-vision/vision-api-how-to-topics/howtocallvisionapi?tabs=python\n",
    "\n",
    "\n",
    "#### 2) 로컬 경로에서 Description 만들 때 : describe_image_in_stream 메써드 사용\n",
    "https://github.com/Azure-Samples/cognitive-services-quickstart-code/blob/master/python/ComputerVision/ImageAnalysisQuickstart.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2d8c5d",
   "metadata": {},
   "source": [
    "### 1. 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbf2d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37a18b6",
   "metadata": {},
   "source": [
    "### 2. 계정 인증하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "934986ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEND - Authenticate\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Authenticate\n",
    "Authenticates your credentials and creates a client.\n",
    "'''\n",
    "\n",
    "#key와 엔드포인트는 azure portal에서 cognitive service를 만들고 나면 가져올 수 있음\n",
    "#현재의 키와 엔드포인트는 내 계정인데, 다른 컴퓨터에서도 돌아갈지는 모르겠음\n",
    "\n",
    "subscription_key = \"9e14cf501b8b4ca98a27c3bb2391e803\"\n",
    "endpoint = \"https://lmg1111111.cognitiveservices.azure.com/\"\n",
    "\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "'''\n",
    "END - Authenticate\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eb3c67",
   "metadata": {},
   "source": [
    "### 3. 이미지 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec737d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEND - Quickstart variables\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Images used for the examples: Describe an image, Categorize an image, Tag an image, \n",
    "# Detect faces, Detect adult or racy content, Detect the color scheme, \n",
    "# Detect domain-specific content, Detect image types, Detect objects\n",
    "\n",
    "#images가 들어간 폴더를 찾는다.\n",
    "images_folder = os.path.join (os.path.dirname(os.path.abspath('')), \"images\")\n",
    "# 아래의 url은 의미없다.\n",
    "remote_image_url = \"https://moderatorsampleimages.blob.core.windows.net/samples/sample16.png\"\n",
    "\n",
    "'''\n",
    "END - Quickstart variables\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea214359",
   "metadata": {},
   "source": [
    "### 4. 분석하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5ed3374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Describe an Image - local =====\n",
      "Description of local image: \n",
      "'a person and a boy looking at a screen' with confidence 37.11%\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEND - Describe an Image - local\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Describe an Image - local\n",
    "This example describes the contents of an image with the confidence score.\n",
    "'''\n",
    "print(\"===== Describe an Image - local =====\")\n",
    "# images 폴더에서 image2.png 파일을 불러온다\n",
    "#혹시나 해서 실험해 봤는데 png든 jpg든 결과에는 관계없다. 확장자에 따라 결과가 달라지지 않는다\n",
    "local_image_path = os.path.join(images_folder, \"image2.png\")\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "\n",
    "# Call API\n",
    "description_result = computervision_client.describe_image_in_stream(local_image)\n",
    "\n",
    "# Get the captions (descriptions) from the response, with confidence level\n",
    "print(\"Description of local image: \")\n",
    "if (len(description_result.captions) == 0):\n",
    "    print(\"No description detected.\")\n",
    "else:\n",
    "    for caption in description_result.captions:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))\n",
    "print()\n",
    "'''\n",
    "END - Describe an Image - local\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622fec89",
   "metadata": {},
   "source": [
    "### 5. 분석결과만 따로 뽑아쓰려면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c099b731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a person and a boy looking at a screen\n"
     ]
    }
   ],
   "source": [
    "#text만 따로 뽑아쓰려면 caption[0].text로 뽑아쓸 수 있다\n",
    "print(description_result.captions[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629ecff3",
   "metadata": {},
   "source": [
    "# 4. TTS 가즈아"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6208d05b",
   "metadata": {},
   "source": [
    "### ※ 참고사항!\n",
    "\n",
    "#### 1. 텍스트 음성 변환\n",
    "https://docs.microsoft.com/ko-kr/azure/cognitive-services/speech-service/get-started-text-to-speech?tabs=terminal&pivots=programming-language-python\n",
    "\n",
    "#### 2. 텍스트 파일 저장\n",
    "https://docs.microsoft.com/ko-kr/azure/cognitive-services/speech-service/how-to-speech-synthesis?tabs=script%2Cbrowserjs%2Cterminal&pivots=programming-language-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949dd940",
   "metadata": {},
   "source": [
    "### 1. 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13fa94a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-cognitiveservices-speech in c:\\users\\ansrl\\anaconda3\\lib\\site-packages (1.21.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install azure-cognitiveservices-speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcce50d",
   "metadata": {},
   "source": [
    "### 2. 스피커로 분석결과를 읽어보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f88e0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter some text that you want to speak >\n",
      "Speech synthesized for text [a person and a boy looking at a screen]\n"
     ]
    }
   ],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "\n",
    "# 여기서도 key와 region은 portal에서 cognitive service를 만들면 뽑을 수 있다\n",
    "speech_config = speechsdk.SpeechConfig(subscription=\"4273fb5b821a4785bc85836bea53d2a1\", region=\"KoreaCentral\")\n",
    "audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "\n",
    "# 제니씨의 음성으로 들어보자\n",
    "speech_config.speech_synthesis_voice_name='en-US-JennyNeural'\n",
    "\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "# Get text from the console and synthesize to the default speaker.\n",
    "print(\"Enter some text that you want to speak >\")\n",
    "\n",
    "#text = input()을 넣으면 따로 내가 출력하고 싶은 글귀를 넣을 수도 있다\n",
    "#일단은 아까의 분석결과를 넣어보도록 하자\n",
    "text = description_result.captions[0].text\n",
    "\n",
    "speech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\n",
    "\n",
    "#스피커로 출력하기\n",
    "if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "    print(\"Speech synthesized for text [{}]\".format(text))\n",
    "elif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n",
    "    cancellation_details = speech_synthesis_result.cancellation_details\n",
    "    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "        if cancellation_details.error_details:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "            print(\"Did you set the speech resource key and region values?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b367bfed",
   "metadata": {},
   "source": [
    "### 3. 파일로 저장해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cdbe21d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.cognitiveservices.speech.ResultFuture at 0x19036c101f0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filename에는 저장할 폴더와 저장할 파일명을 넣으면 됩니다.\n",
    "audio_config = speechsdk.audio.AudioOutputConfig(filename=\"C:/Users/ansrl/Documents/이문기/11_TAVE/2022 AI_SPARK/jeiyoon.wav\")\n",
    "synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "synthesizer.speak_text_async(description_result.captions[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab19259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
